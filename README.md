# ğŸ§  SahAI â€“ Your Personal Family Assistant

This project demonstrates a practical, end-to-end implementation of a local RAG-based assistant.

A **100% local, private Retrieval-Augmented Generation (RAG) chatbot** built using **Ollama**, **LangChain**, **ChromaDB**, and **Flask**.
It acts as a **fictional family personal assistant**, answering questions about family members, appointments, routines, and activities â€” all **offline** and under your control.


> âš ï¸ **Disclaimer**
> All family data used in this project is **entirely artificial and fictional**.
> Any resemblance to real persons, living or dead, or real events is **purely coincidental**.
> This project is for **learning and demonstration purposes only**.

---
## ğŸ“¸ Screenshots

### Main Interface
![main UI](screenshots/ui-home.png)

### Question & Answer Example
![Q&A Example](screenshots/qa-example.png)

### Remember Command
![Remember Command](screenshots/remember-command.png)


## âœ¨ Features

* ğŸ”’ **100% Local** â€“ runs fully offline using Ollama
* ğŸ“š **RAG-based Q&A** â€“ answers only from your documents
* ğŸ§  **Conversation memory** â€“ remembers chat context
* ğŸ—‚ï¸ **Vector search (ChromaDB)** â€“ fast and accurate retrieval
* ğŸŒ **Web UI** â€“ simple Flask-based interface
* âœï¸ **"Remember:" command** â€“ append new facts to knowledge base

---

## ğŸ—ï¸ Architecture Overview

```
User (Browser)
   â†“
Flask Web App
   â†“
LangChain (Conversational RAG)
   â†“
ChromaDB (Vector Store)
   â†“
Ollama (phi LLM + embeddings)
   â†“
family.txt (Fictional Knowledge Base)
```

---

## ğŸ“ Project Structure

```
rag-chatbot/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ family.txt          # Fictional family knowledge
â”œâ”€â”€ chroma_db/              # Vector database (auto-generated)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ rag_engine_with_history.py
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ app.py              # Flask application
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html      # Web UI
â”œâ”€â”€ rag-env/                # Python virtual environment
â”œâ”€â”€ requirments.txt
â””â”€â”€ README.md
```

---

## ğŸ§° Requirements

* Python **3.10+**
* Ollama installed and running
* At least **6â€“8 GB RAM** recommended

### Python packages (installed in venv):

* flask
* langchain
* langchain-community
* langchain-text-splitters
* chromadb

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Create & activate virtual environment

```bash
cd /rag-chatbot
python3 -m venv rag-env
source rag-env/bin/activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Install & start Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama --version
ollama pull phi
ollama pull nomic-embed-text
ollama serve
```

---

## ğŸ“„ Knowledge Base

Edit the fictional family data here:

```
docs/family.txt
```

This file contains:

* Family members
* Relationships
* Appointments
* Weekly activities
* Preferences & routines

âš ï¸ Changes require application restart (by design).

---

## ğŸ§  RAG Engine

Located at:

```
scripts/rag_engine_with_history.py
```

### Key components:

* **TextLoader** â€“ loads `family.txt`
* **RecursiveCharacterTextSplitter** â€“ chunks text
* **OllamaEmbeddings** â€“ converts text â†’ vectors
* **ChromaDB** â€“ stores vectors
* **ConversationalRetrievalChain** â€“ handles Q&A + memory

---
## ğŸ§  Start phi before App

```bash
 ollama run phi    
```

## ğŸŒ Run the Web App

```bash
cd web
/rag-chatbot/rag-env/bin/python3  app.py
```

Open browser:

```
http://<your-ip>:5000
```

---

## ğŸ’¬ Example Questions

* Who is Mark?
* Who are Markâ€™s family members?
* When is Judeâ€™s next dental appointment?
* What activities does Lily have this week?


---

## âœï¸ "Remember:" Command

You can add new knowledge during chat:

```
Remember: Mark's mother Helen is visiting next weekend
```

âœ” Appends to `family.txt`
âœ” Acknowledged immediately
âš ï¸ Becomes searchable **after app restart**

---

## ğŸ”§ Troubleshooting

### ğŸŒ€ Model Hallucinations or Inaccurate Responses

If the system starts producing inaccurate or hallucinated responses, it may be due to outdated or inconsistent vector embeddings.

To recover:

1. **Stop the application**
2. **Update the source data**
   - Edit or correct the contents of `family.txt`
3. **Rebuild the vector database**
   ```bash
      rm -rf /rag-chatbot/chroma_db
   ```
4. Restart the application to allow embeddings to be regenerated from the updated data.

This process ensures the vector store remains consistent with the latest source documents.

## ğŸ” Security Notes

* Uses `app.secret_key` for Flask session security
* Designed for **local / private use only**
* Do not expose publicly without authentication

---

## ğŸ§  Limitations (By Design)

* No hot-reload of vector DB (avoids corruption)
* Single-user chat memory
* Fictional data only

---

## ğŸ›£ï¸ Future Improvements

### ğŸ”Š Voice-Based Personal Assistant (Next Level)

A natural next step is to evolve this Flask web app into a **voice-driven personal assistant**.

**Proposed Architecture:**

```
Microphone
   â†“
Speech-to-Text (STT)
   â†“
RAG API (FastAPI instead of Flask)
   â†“
LangChain + ChromaDB + Ollama
   â†“
Text Response
   â†“
Text-to-Speech (TTS)
   â†“
Speaker
```

**Key Changes:**

* Replace Flask UI with **FastAPI** (API-first design)
* Use **Speech-to-Text (STT)** models:

  * Whisper (local)
  * Vosk
* Convert responses to audio using **Text-to-Speech (TTS)**:

  * Piper (local)
  * Coqui TTS
* Run on:

  * Raspberry Pi
  * Mini PC
  * Old laptop

**Result:**
A fully local, privacy-first **personal assistant speaker** â€” no cloud, no tracking.

---

## ğŸ›£ï¸ More Future Improvements

* Auto-reindex with file locks
* Multi-user sessions
* Streaming responses
* Authentication
* Calendar export (ICS)
* Voice input/output

---

## ğŸ Final Notes

This project is meant as a **learning-friendly, realistic RAG system**, not a production cloud app.

You now have:

* A working local LLM assistant
* Document-grounded answers
* Conversational memory
* Full control over data

ğŸš€ Well done â€” this is real applied AI engineering.


## ğŸ“„ License

This project is licensed under the MIT License.
See the [LICENSE](LICENSE) file for details.
